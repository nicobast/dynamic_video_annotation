---
title: "IRR_video_annotations"
author: "Nico Bast"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_float: yes
    number_sections: yes
    theme: cerulean
    code_folding: hide
  word_document:
    toc: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) #show code in markdown

## packages
require(openxlsx)
require(ggplot2)
require(psych) #IRR metric


theme_set(theme_bw())

## paths
path<-'C:/Users/nico/PowerFolders/project_dynamic/video_annotations'

##required functions
###time conversion
fun_timeconv<-function(x){
  as.POSIXct(x,format = "%H:%M:%OS") #consider fractional seconds = milliseconds with %OS
}

###task selection function
fun_seltask<-function(x,var_name){
x<-x[,names(x) %in% c('Number','Onset_Time','Offset_Time',var_name)]
}
```

# provide settings

- selct the rater in code (Rosa, Merlinda, Paula)
- select the rating category (Mutual, Avert, Refer, Follow, Share, Supporting.gesture, Supporting.behavior, Transcript)
- select the time frame of the benchmark sequence

```{r manual settings}

# rating_category<-'Avert'
# cutoff<-as.POSIXct("00:05:00",format = "%H:%M:%OS") #time frame
rating_category<-'Share'

#rater names
rater1_name<-'Paula'
rater2_name<-'Merlinda'

#rating time
cutoff_min<-399
cutoff_max<-1400

```

# read and select data

- reads INTERACT output for two rater and selects a specific sequences of a task

```{r read and select data}

#select rater data
# rater2<-read.xlsx(paste0(path,'/data/FRA_038_T5_ESCS_Übereinstimmung.xlsx'),sheet = 2) #MERLINDA
# rater1<-read.xlsx(paste0(path,'/data/FRA_038_T5_ESCS_Übereinstimmung.xlsx'),sheet = 1,rows = 1:309) #ROSA
rater2<-read.csv(paste0(path,'/data/FRA_105_T2_ESCS_Coding_MB.csv'),sep=';',dec=',') #MERLINDA
rater1<-read.csv(paste0(path,'/data/FRA_105_T2_ESCS_Coding_PN.csv'),sep=';',dec=',') #PAULA

#convert time data
# rater1$Offset_Time<-fun_timeconv(rater1$Offset_Time)
# rater1$Onset_Time<-fun_timeconv(rater1$Onset_Time)
# rater2$Offset_Time<-fun_timeconv(rater2$Offset_Time)
# rater2$Onset_Time<-fun_timeconv(rater2$Onset_Time)
rater1$Offset_Time<-as.numeric(rater1$Offset_Time)
rater1$Onset_Time<-as.numeric(rater1$Onset_Time)
rater2$Offset_Time<-as.numeric(rater2$Offset_Time)
rater2$Onset_Time<-as.numeric(rater2$Onset_Time)

#select a task based on timestamp
rater1_task1<-rater1[rater1$Onset_Time<cutoff_max & rater1$Onset_Time>cutoff_min,]
rater2_task1<-rater2[rater2$Onset_Time<cutoff_max & rater2$Onset_Time>cutoff_min,]

#select a rating category
rater1_task1_category<-fun_seltask(rater1_task1,rating_category)
rater2_task1_category<-fun_seltask(rater2_task1,rating_category)

```

# Plot annotations for a category

Figure shows the number of annotated gaze events (x-axis) and onset and offset of that event (y-axis).
Overlap in Ratings can be done by looking at horizontal overlap at any given timepoint.

displayed rating category: `r rating_category`


```{r pressure, echo=FALSE, fig.height=10}

table(rater1_task1_category[,rating_category])
table(rater2_task1_category[,rating_category])

#combine onset and offset data with rater for plotting
y1<-rater1_task1_category[grepl(rating_category,rater1_task1_category[,rating_category]),
                          names(rater1_task1_category) %in% c('Onset_Time','Offset_Time')]
y1$rater<-rater1_name
y1$seq<-1:nrow(y1)

y2<-rater2_task1_category[grepl(rating_category,rater1_task1_category[,rating_category]),
                          names(rater2_task1_category) %in% c('Onset_Time','Offset_Time')]
y2$rater<-rater2_name
y2$seq<-1:nrow(y2)
df<-rbind(y1,y2)

ggplot(df,aes(x=Onset_Time,y=Offset_Time,group=rater,color=rater))+geom_point(alpha=0.5)

ggplot(df) +
  geom_segment(aes(x = seq, xend = seq, y = Onset_Time, yend = Offset_Time,color=rater,linewidth=3)) +
  labs(title = "Bars with Onset and Offset on Y-axis",
       x = paste("gaze event number (gaze event:",rating_category,")"),
       y = "segment duration")
  
```

# Create Matrix for calculating Inter-Rater-Reliability

- matrix is calculated per every 10ms. This is also the time resolution provided by INTERACT coding software
- function creates a matrix that alligns rating time frames between raters that is used for a contingency table

```{r IRR matrix}

# convert to matrix to define inter-rater reliability

##create a matrix - function takes interact ratings and creates vector in tenth of second format with according rating label
fun_rater_vector<-function(rating_df){

###get max time
#max_time<-format(max_time,"%H:%M:%OS2") #backconverted to character
max_time<-max(rating_df$Offset_Time)
min_time<-min(rating_df$Onset_Time)


###calculate the number of tens of seconds 
# vector_rows<-as.numeric(substr(max_time,1,2))*360000+
#   as.numeric(substr(max_time,4,5))*6000+
#   as.numeric(substr(max_time,7,8))*100+
#   as.numeric(substr(max_time,10,11))
vector_rows<-(max_time-min_time)*100

#length of rater vector based on rated time
rater_vector<-rep(NA,vector_rows)

#function that fills a vector with categories based on ratings
for(i in 1:nrow(rating_df)){
#start_row<-round(as.numeric(difftime(rating_df$Onset_Time[i],min(rating_df$Onset_Time),units='secs'))*100)
#end_row<-round(as.numeric(difftime(rating_df$Offset_Time[i],min(rating_df$Onset_Time),units='secs'))*100)
start_row<-round((rating_df$Onset_Time[i]-min(rating_df$Onset_Time))*100)
end_row<-round((rating_df$Offset_Time[i]-min(rating_df$Onset_Time))*100)
category<-rating_df[i,rating_category]
if(category==''){category<-'NONE'}

#print(c(i,start_row,end_row,category)) #DEBUGGING

rater_vector[start_row:end_row]<-category
}

return(rater_vector)
  
}

#convert to vector
rater1_vector<-fun_rater_vector(rating_df=rater1_task1_category)
rater2_vector<-fun_rater_vector(rating_df=rater2_task1_category)

# #reduce to one rating
# rater1_vector<-ifelse(grepl(rating_category,rater1_vector),rating_category,'NONE')
# rater2_vector<-ifelse(grepl(rating_category,rater2_vector),rating_category,'NONE')

#consider rating timing offset between raters
rater1_start_timing<-min(rater1_task1_category$Onset_Time)
rater2_start_timing<-min(rater2_task1_category$Onset_Time)
start_timing_diff<-round((rater1_start_timing-rater2_start_timing)*100)

#create a matrix combing ratings, consider different lengths and differently rated timeframes
earliest_start<-min(c(rater1_task1_category$Onset_Time,rater2_task1_category$Onset_Time))
latest_end<-max(c(rater1_task1_category$Offset_Time,rater2_task1_category$Offset_Time))
maxtrix_rows<-(latest_end-earliest_start)*100

if(sign(start_timing_diff)==-1){
  rating_df<-data.frame(matrix(NA, nrow=maxtrix_rows,ncol=2))
  rating_df$X1[1:length(rater1_vector)]<-rater1_vector
  rating_df$X2[(abs(start_timing_diff)):(abs(start_timing_diff)+length(rater2_vector)-1)]<-rater2_vector
  }

if(sign(start_timing_diff)==1){
  rating_df<-data.frame(matrix(NA, nrow=maxtrix_rows+1,ncol=2))
  rating_df$X1[(abs(start_timing_diff)):(abs(start_timing_diff)+length(rater1_vector)-1)]<-rater1_vector
  rating_df$X2[1:length(rater2_vector)]<-rater2_vector
  }

#final analysis
table(rater1_vector) #ratings rater 1
table(rater2_vector) #ratings rater 2
table(rating_df[,1],rating_df[,2]) #contingency table
cohen.kappa(rating_df) #IRR
irr::kappa2(rating_df, weight = 'equal') #IRR with disagreement is weighted
irr::kappam.fleiss(rating_df)

```

